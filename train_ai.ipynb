{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_multiplier = 10   # increase the size of the subset by taking random composition of CCD\n",
    "epoch = 60                # number of epochs for each AI\n",
    "n = 25                    # number of loops for the genertic algorithm\n",
    "K = 3                     # number of folds (= number of independant AI per generation)\n",
    "\n",
    "train_on = \"triplets\"     # \"triplets\" or \"blocks\"\n",
    "function = \"tan\"          # \"tan\" or \"square\"\n",
    "train_with = \"parameters\" # \"parameters\" or \"points\" TODO\n",
    "\n",
    "train_prop = 0.7          # proportion of the dataset used for training\n",
    "\n",
    "weights = [7.686424453317564,2.8124992994763316,0.448360122048755,4.727911837705288] # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys, copy\n",
    "import data_io\n",
    "import utils.archive as archive\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas            as pd\n",
    "import tensorflow        as tf\n",
    "from   IPython.display   import display\n",
    "from   tensorflow        import keras\n",
    "from   classes.block     import Block\n",
    "from   classes.triplet   import Triplet\n",
    "from   classes.shot      import Shot\n",
    "from   classes.ccd       import CCD\n",
    "from   classes.rate      import Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(x_train,y_train):\n",
    "    # mse = tf.keras.losses.MeanSquaredError()\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input((len(x_train[0]),), name=\"InputLayer\"))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', name='Dense_n1'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', name='Dense_n2'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', name='Dense_n3'))\n",
    "    model.add(keras.layers.Dense(len(y_train), name='Output'))\n",
    "    model.compile(optimizer = 'adam', loss = 'mse', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of efficiency functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tan\n",
    "def ft(m,a,b,c,d):\n",
    "    return a/4 * (1-np.tanh((m-b)/c)) * (1-np.tanh((m-b)/d))\n",
    "\n",
    "# square\n",
    "def fs(m,a,b,c,d):\n",
    "    return (a-b*(m-21)**2) / (1+np.exp((m-c)/d))\n",
    "\n",
    "# magnitude range\n",
    "m = np.linspace(21,25.5,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data and creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2013AE.json\n",
      "Loading 2013AO.json\n",
      "Loading 2013BL.json\n",
      "Loading 2014BH.json\n",
      "Loading 2015AM.json\n",
      "Loading 2015AP.json\n",
      "Loading 2015BC.json\n",
      "Loading 2015BD.json\n",
      "Loading 2015BS.json\n",
      "Loading 2015BT.json\n",
      "1610 vectors containing 1728 inputs and 4 outputs\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "data_io.loadAll() # comment if already loaded to spare time\n",
    "\n",
    "# Formating data in data set usable by the AI\n",
    "data, outputs = data_io.get_ai_ready(items = Triplet.all, func=function,subsets_per_block=subset_multiplier)\n",
    "\n",
    "print(len(data), \"vectors containing\", len(data[0])-outputs, \"inputs and\", outputs, \"outputs\")\n",
    "\n",
    "# Normalization\n",
    "mean = data[:,:-outputs].mean()\n",
    "std  = data[:,:-outputs].std()\n",
    "data[:,:-outputs] = (data[:,:-outputs] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting a random test item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test item: 15AM+1-1\n"
     ]
    }
   ],
   "source": [
    "if train_on == \"blocks\":\n",
    "    test_item = iter(Block.all.values())[np.random.randint(0,len(Block.all)-1)]\n",
    "if train_on == \"triplets\":\n",
    "    tripletList = []\n",
    "    for rate in Rate.all:\n",
    "        if type(rate.parent) == Triplet and rate.parent.id not in tripletList:\n",
    "            tripletList.append(rate.parent.id)\n",
    "    test_item = Triplet.all[tripletList[np.random.randint(0,len(tripletList)-1)]]\n",
    "\n",
    "print(\"Test item:\",test_item.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on test item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(test_item, model):\n",
    "    if test_item.to_ai_ready(func=\"tan\") is not None:\n",
    "        new_data,outputs = test_item.to_ai_ready(func=\"tan\")\n",
    "    else:\n",
    "        new_data,outputs = test_item.to_ai_ready(func=\"square\")\n",
    "\n",
    "    new_x = new_data[:-outputs]\n",
    "    new_y = new_data[-outputs:]\n",
    "    new_x = (new_x - mean) / std\n",
    "\n",
    "    new_x=np.array(new_x).reshape(1,len(new_x))\n",
    "\n",
    "    predictions = model.predict(new_x)\n",
    "\n",
    "    print(f\"Prediction : {predictions[0]}\")\n",
    "\n",
    "    # Plotting the result\n",
    "\n",
    "    plt.subplot(int(np.ceil(np.sqrt(n))),int(np.ceil(np.sqrt(n))),i+1)\n",
    "    plt.plot(m, ft(m,*predictions[0]),                     label=\"Machine Learning\")\n",
    "    plt.plot(m, fs(m,new_y[0],new_y[1],new_y[2],new_y[3]), label=\"Excpected\")\n",
    "    plt.grid()\n",
    "\n",
    "    if i == 0:                    plt.title(f\"Predition for {train_on} {test_item.id}\")\n",
    "    if i+1>n-np.ceil(np.sqrt(n)): plt.xlabel(\"Magnitude\")\n",
    "    if i%np.ceil(np.sqrt(n))==0:  plt.ylabel(\"Efficiency\")\n",
    "    if i==0:                      plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cenerating folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(K, data, train_prop, outputs):\n",
    "\n",
    "    # Creating folds\n",
    "    folds = []\n",
    "    for j in range(K):\n",
    "        folds.append(data[j::K])\n",
    "\n",
    "    # Splitting data for training and test...\n",
    "    Xt_list = []; Yt_list = []; Xv_list = []; Yv_list = []\n",
    "    for j, fold in enumerate(folds):\n",
    "        train_sets = int(len(fold)*train_prop)\n",
    "        index = np.zeros(len(fold),dtype=bool)\n",
    "        index[:train_sets] = True\n",
    "        np.random.shuffle(index)\n",
    "\n",
    "        data_train = fold[index]\n",
    "        data_test  = fold[~index]\n",
    "\n",
    "        Xt_list.append(data_train[:,:-outputs])\n",
    "        Yt_list.append(data_train[:,-outputs:])\n",
    "        Xv_list.append(data_test [:,:-outputs])\n",
    "        Yv_list.append(data_test [:,-outputs:])\n",
    "\n",
    "    # Composing training data using fold != j\n",
    "    for j in range(K):\n",
    "        Xt_list[j] = np.concatenate(np.array(Xt_list)[np.arange(len(Xt_list))!=j])\n",
    "        Yt_list[j] = np.concatenate(np.array(Yt_list)[np.arange(len(Yt_list))!=j])\n",
    "\n",
    "    return np.array(Xt_list), np.array(Yt_list), np.array(Xv_list), np.array(Yv_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Xt,Yt,Xv,Yv,epoch):\n",
    "    h = models[j].fit(Xt, Yt, epochs = epoch, verbose = 0)        #, validation_data = (x_test[j], y_test[j])\n",
    "    s = models[j].evaluate(Xv, Yv, verbose=0)\n",
    "    return h,s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keeping only the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(generation, models, scores, lastScore):\n",
    "    minScore = lastScore\n",
    "    output.write(f\"{generation+1}, \")\n",
    "    if minScore is None: minScore = scores[0][0]\n",
    "    if model is None: model = models[0]\n",
    "    average = 0\n",
    "    for j,s in enumerate(scores):\n",
    "        output.write(f\"{s[0]}, \") \n",
    "        average += s[0]/K\n",
    "        if s[0] < minScore:\n",
    "            minScore = s[0]\n",
    "            model = models[j]\n",
    "    output.write(f\"{average}, {minScore}\\n\")\n",
    "    return model, minScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training neural nework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Generation 1/25\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\Vincent\\Dev\\Compuphys\\M1-TNO_Detection_Efficiency\\train_ai.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Vincent/Dev/Compuphys/M1-TNO_Detection_Efficiency/train_ai.ipynb#ch0000011?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39müîÅ Generation \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mn\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Vincent/Dev/Compuphys/M1-TNO_Detection_Efficiency/train_ai.ipynb#ch0000011?line=14'>15</a>\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mshuffle(data)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Vincent/Dev/Compuphys/M1-TNO_Detection_Efficiency/train_ai.ipynb#ch0000011?line=16'>17</a>\u001b[0m Xt_list, Yt_list, Xv_list, Yv_list \u001b[39m=\u001b[39m create_folds(K, data, train_prop, outputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Vincent/Dev/Compuphys/M1-TNO_Detection_Efficiency/train_ai.ipynb#ch0000011?line=19'>20</a>\u001b[0m \u001b[39m################################################################################\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Vincent/Dev/Compuphys/M1-TNO_Detection_Efficiency/train_ai.ipynb#ch0000011?line=20'>21</a>\u001b[0m \u001b[39m# Training K models independently\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Vincent/Dev/Compuphys/M1-TNO_Detection_Efficiency/train_ai.ipynb#ch0000011?line=22'>23</a>\u001b[0m models \u001b[39m=\u001b[39m []; history \u001b[39m=\u001b[39m []; scores \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32mf:\\Vincent\\Dev\\Compuphys\\M1-TNO_Detection_Efficiency\\train_ai.ipynb Cell 16'\u001b[0m in \u001b[0;36mcreate_folds\u001b[1;34m(K, data, train_prop, outputs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Vincent/Dev/Compuphys/M1-TNO_Detection_Efficiency/train_ai.ipynb#ch0000017?line=23'>24</a>\u001b[0m \u001b[39m# Composing training data using fold != j\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Vincent/Dev/Compuphys/M1-TNO_Detection_Efficiency/train_ai.ipynb#ch0000017?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(K):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Vincent/Dev/Compuphys/M1-TNO_Detection_Efficiency/train_ai.ipynb#ch0000017?line=25'>26</a>\u001b[0m     Xt_list[j] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(Xt_list[np\u001b[39m.\u001b[39;49marange(\u001b[39mlen\u001b[39;49m(Xt_list))\u001b[39m!=\u001b[39;49mj])\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Vincent/Dev/Compuphys/M1-TNO_Detection_Efficiency/train_ai.ipynb#ch0000017?line=26'>27</a>\u001b[0m     Yt_list[j] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(Yt_list[np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(Yt_list))\u001b[39m!=\u001b[39mj])\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Vincent/Dev/Compuphys/M1-TNO_Detection_Efficiency/train_ai.ipynb#ch0000017?line=28'>29</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(Xt_list), np\u001b[39m.\u001b[39marray(Yt_list), np\u001b[39m.\u001b[39marray(Xv_list), np\u001b[39m.\u001b[39marray(Yv_list)\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "minScore = None\n",
    "path = archive.new(name = archive.description(M = subset_multiplier, N = n, K = K, E = epoch))\n",
    "output = open(f\"{path}/ouput.csv\",\"w\")\n",
    "\n",
    "output.write(\"Generation, \")\n",
    "for j in np.arange(K): output.write(f\"Score of model {j}, \")\n",
    "output.write(\"Average, Score retained\\n\")\n",
    "\n",
    "# Loop over generations (genetic algorithm)\n",
    "for i in range(n):\n",
    "  \n",
    "  print(f\"üîÅ Generation {i+1}/{n}\")\n",
    "\n",
    "  np.random.shuffle(data)\n",
    "\n",
    "  Xt_list, Yt_list, Xv_list, Yv_list = create_folds(K, data, train_prop, outputs)\n",
    "  \n",
    "\n",
    "  ################################################################################\n",
    "  # Training K models independently\n",
    "\n",
    "  models = []; history = []; scores = []\n",
    "  for j in range(K):\n",
    "\n",
    "    print(f\"üèÉ‚Äç‚ôÄÔ∏è Training model  with fold {j} as test...\", end=\"\\r\")\n",
    "\n",
    "    # Sub sets for this fold\n",
    "\n",
    "    Xt, Yt, Xv, Yv = Xt_list[j], Yt_list[j], Xv_list[j], Yv_list[j]\n",
    "\n",
    "    # Getting new model if it's the first generation, and the old one if not\n",
    "\n",
    "    if len(models) < j+1: models.append(get_model(Xt,Yt))\n",
    "    else: models.append(model)\n",
    "\n",
    "    # Training models\n",
    "\n",
    "    res, score = train(Xt, Yt, Xv, Yv, epoch)\n",
    "    history.append(res)\n",
    "    scores.append(score)\n",
    "\n",
    "  # Keeping the best one\n",
    "\n",
    "  model, lastScore = get_best_model(i,models, scores, lastScore)\n",
    "\n",
    "  # Making new prediction\n",
    "\n",
    "  print(\"üîÆ Prediction...\")\n",
    "  prediction()\n",
    "\n",
    "################################################################################\n",
    "# Saving results\n",
    "\n",
    "output.close()\n",
    "plt.savefig(f\"{path}/tno_efficiency_rate.png\")\n",
    "model.save(f\"{path}/model.ckpt\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0d398e7c3cc3d2b8386dfea47f5eae3378d5d39db7e2c8ef87e93246db0bfd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
